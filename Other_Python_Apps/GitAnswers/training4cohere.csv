Prompt,Text
,"# **Building a C# enhancing app using OpenAI GPT-4 and Streamlit**  This repository contains an application designed to enhance a provided C# file from your local computer.  To achieve these functionalities, we will leverage the capabilities of the Azure OpenAI GPT-4 model and Streamlit (for the user interface).  Keep in mind that it is a simple app that I put together in just a couple of hours,  I'm sure that the prompts that we're sending to OpenAI GPT-4 can be further improved.  # **Content**  This app has the following capabilities when working with a csharp file:  - It can add or enhance existing XML comments. - It can offer detailed code explanations. - It provides valuable suggestions for code improvements. - It can create Unit Tests that uses xUnit and Moq.  > **OpenAI GPT-4 is an incredibly valuable tool, but it's important not to blindly rely on its results. Before using any output generated by this application in a real-world scenario, review it throughly. Ensure that the generated XML comments are well-defined, check if the unit tests are actually valuable or not, and critically evaluate whether the suggestions it provides for your C# code actually make sense or not.**  ![app-screenshot](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-homescreen.png)  # External dependencies  The app uses the following technologies:  - [Azure OpenAI](https://azure.microsoft.com/en-us/products/cognitive-services/openai-service) - [Streamlit](https://streamlit.io/)  # Prerequisites  Before trying to execute the app, you must have the following services running:  - A running ``Azure OpenAI`` instance with a ``gpt-4`` or ``gpt-4-32k`` deployed on it.  # **How to run the app**  > Before trying to run the app, read the _Prerequisites_ section.  ## **Run the app locally**  ### **Set the required environment variables**  The repository has a ``.env`` file that contains the environment variables that the app requires to run successfully:  ```text AZURE_OPENAI_APIKEY=<azure-openai-apikey> AZURE_OPENAI_BASE_URI=<azure-openai-url> AZURE_OPENAI_GPT4_MODEL_NAME=<azure-openai-gpt4-deployment-name> ``` Change the values accordingly.  ### **Restore dependencies**  ```bash pip install -r requirements.txt ``` ### **Run the app**  When you install ``Streamlit``, a command-line (CLI) tool gets installed as well. The purpose of this tool is to run ``Streamlit`` apps. To execute the app, just run the following command: ```bash streamlit run app.py ```  ## **Run the app using Docker**  > This repository has a ``Dockerfile`` in case you prefer to execute the app on a container.  ### **Build the image**  ```shell docker build -t csharp-enhancing-app . ```  ### **Run it**  ``` docker run -p 5050:5050 \ -e AZURE_OPENAI_APIKEY=""ba2fc5d3c3e044c3948e7ef7289d74ba"" \ -e AZURE_OPENAI_BASE_URI=""https://cog-c75hs7cjsi3h6.openai.azure.com"" \ -e AZURE_OPENAI_GPT4_MODEL_NAME=""gpt-4-32k"" \ csharp-enhancing-app ```  # **Result**  This is what you'll see once you start interacting with app.  - When you upload a csharp file, the file source code can be viewed in a code block.  ![app-upload](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-upload-source-code.png)  - When you run the _""Add XML comments""_ functionality, the result is displayed in another code block.  ![app-xml-comments-result](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-xml-comments-source-code.png)  - Here's the explanation given by GPT-4 when you run the _""Explain code""_ functionality.  ![app-explain-code](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-explain-code.png)  - Here's an example of the suggestions given by GPT-4 when you run the _""Suggest code improvements""_ functionality.  ![app-suggestions](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-code-suggestions.png)  - When you run the _""Generate unit tests""_ functionality, the result is displayed in a code block.  ![app-unit-test](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-unit-test-generation.png)  - If you try to generate unit tests from a file which makes no sense (e.g. ``Program.cs``), the response will be that no tests are available.  ![app-no-unit-test](https://raw.githubusercontent.com/karlospn/building-a-csharp-enhancing-app-with-openai-and-streamlit/main/imgs/enhancing-csharp-app-no-unit-test-generation.png)"
,"<!-- 1. First, install the prerequisites --> pip install -r requirements.txt  <!-- 2. Instead of using standard ""python main.py"" for launch, use next command: --> python -m streamlit run main.py --server.port 8003"
,"# Zero-Shot Sentiment Analysis with GPT-3.5-turbo  This repository contains an interactive Streamlit application that utilizes OpenAI's GPT-3.5-turbo model for zero-shot sentiment analysis. Users input a piece of text, and the application classifies the sentiment based on predefined emotions, displays the results, and maintains a history of past analyses.  ## Features  - Zero-Shot Sentiment Analysis: Using GPT-3.5-turbo, this application provides an intuitive interface for performing zero-shot sentiment analysis. - Sentiment History: Keeps track of all the sentiment analysis done during a session, providing a comprehensive review of the session's analysis.  ## Requirements  - Python 3.6+ - OpenAI API key - Streamlit - python-dotenv - openai  ## Setup  1. Clone this repository to your local machine. 2. Install the required packages: ``` pip install -r requirements.txt ``` 3. Create a `.env` file in the root directory and add your OpenAI API key: ``` OPENAI_API_KEY=your-api-key-here ``` 4. Run the Streamlit app: ``` streamlit run sentiment_analysis.py ```  ## Usage  1. Launch the application and input the text you want to analyze in the provided text area. 2. Click 'Check!' and the application will classify the sentiment of the text based on predefined emotions. 3. The result is displayed below the 'Check!' button, and the history is maintained in the 'History' text area.  ## Example sentiments  ![Example of Sentiment](image.png)  ## Example True or false  ![Example of True or False](image2.png)  ## Contributing  Contributions to this project are welcome! Please feel free to open an issue or submit a pull request.  ## License  This project is licensed under the terms of the MIT license. For more information, please see the [LICENSE](LICENSE) file."
,"# Takweed-GPT  GPT üß† for chat with CSV, PDF, TXT files ü§ñ and YTB videos üî¥ | using Langchain üê¶ | OpenAI | Streamlit  ![architecture](architecture.webp)  ## Running Locally üíª  Follow these steps to set up and run the service locally :  ### Prerequisites  - Docker - Python3  ### Installation  Clone the repository :  `git clone git@github.com:Mahaseel-Lab/Takweed-GPT.git`  Navigate to the project directory :  `cd Takweed-GPT`  Create a virtual environment :  ```bash python -m venv .venv .\.venv\Scripts\activate ```  Install and Launch the chat service locally :  `pip install -r requirements.txt`  `streamlit run src/Home.py`  #### That's it! The service is now up and running locally.  ## Contributing üôå  If you want to contribute to this project, please open an issue, submit a pull request or contact me at ahmed.khaled@mahaseel.net ü§ó"
,"# PDF Question Answering Application  ![Logo](src/logo.png)  This application is an AI-based solution built with Python and Streamlit. It utilizes various libraries like `PyPDF2`, `dotenv`, `FAISS` and OpenAI's `GPT-4` to provide answers to user queries about the content in a PDF document. Users can upload a PDF document and ask questions related to the document. The AI model scans the PDF, extracts relevant information, and responds to user queries in real time.  ## Installation  You will need Docker to run this application. Docker makes it easy to create, deploy, and run applications by using containers. If you haven't installed Docker, please follow the instructions on the [official Docker website](https://docs.docker.com/get-docker/).  ## Setup  ### Step 1: Clone the repository  Clone the repository using the following command in your terminal:  ```bash git clone https://github.com/lucasikruger/PDF-question-answer-llm-langchain-streamlit ```  ### Step 2: Set up the .env file  You will need to create a `.env` file to store your OpenAI API Key. Create a new file named `.env` **in the `./src` directory** of the project and add the following line to it:  ```bash OPENAI_API_KEY=your_openai_api_key ```  Replace `your_openai_api_key` with your actual OpenAI API key.  ### Step 3: Build and run the Docker container  Navigate to the project's root directory in your terminal and run the following command to build and run the Docker container:  ```bash docker-compose up ```  This command will build the Docker image and run the container. The Streamlit server is exposed on port `8501` of your machine.  You can access the application by opening a web browser and visiting `http://localhost:8501`.  ## Usage  To use the application, follow these steps:  1. Upload a PDF file by clicking the ""Upload your PDF"" button. 2. Enter your question about the content of the PDF in the ""Write your question and press ENTER."" text field. 3. The application will process your question, analyze the PDF content, and provide the most accurate answer it can find.  Here's an example of how the application looks and functions:  ![Example Image](img.png)  ---  ## Support  If you encounter any issues or have any questions about this application, please open a GitHub issue or submit a pull request.  ## License  This project is open source and available under the [MIT License](LICENSE).  ---  We hope you find this application useful, and we look forward to your contributions!"
,"# IABusinessAgent Made with streamlit at least it will be one of the powerful business IA agent CRM using GPT 3.5 Turbo for mailing, fit gap and feedbacks"
,"# BusinessEditorialBot  The Business Editorial Bot App is a Streamlit application that leverages the power of OpenAI's GPT-3.5-turbo model to generate summaries of business articles. You can paste the URL of an article, select the desired tone (e.g., professional, witty, engaging, or casual), and the app will produce a summarised version of the article in the chosen tone.  The output can be downloaded as a .docx file for further use.  <img width=""941"" alt=""Screenshot 2023-07-08 at 6 03 32 PM"" src=""https://github.com/victorkjung/BusinessEditorialBot/assets/123326026/b54a7c44-f1c2-4dcf-b09f-87a1f9408e8d"">  **Getting Started**  To get a local copy up and running, follow these simple steps.  **Prerequisites**  This project requires Python 3.6+ and the following libraries installed:  **Streamlit**  pandas openai python-docx You can install these using pip:  <img width=""642"" alt=""Screenshot 2023-07-08 at 6 06 20 PM"" src=""https://github.com/victorkjung/BusinessEditorialBot/assets/123326026/595d7dc6-1c3a-40d9-8bfd-6f844a1ea6f5"">   After launching the app, paste the URL of the business article in the 'Enter the URL' field, select the desired tone of the article summary, then click 'Generate'. You will then need to enter your OpenAI API key. After the summary is generated, review and edit the draft if needed before clicking 'Publish' to generate the final version. You can then download the generated summary as a .docx file.  Running on GPT 3.5; the queries are less than a penny a request. This is very economical solution to the paying for other SAAS programs as you are still experimenting and exploring the world of python, its libraries like Streamlit, pandas, LLM language models, and ChatGPT (Chat Generative Pre-Trained Transformer) the artificial intelligence chatbot developed by OpenAI.  <img width=""847"" alt=""Screenshot 2023-07-08 at 6 07 35 PM"" src=""https://github.com/victorkjung/BusinessEditorialBot/assets/123326026/0f6e596f-bd90-4266-80ab-b70f639c0a95"">  **Contributing**  Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.  **Fork the Project** Create your Feature Branch (git checkout -b feature/AmazingFeature) Commit your Changes (git commit -m 'Add some AmazingFeature') Push to the Branch (git push origin feature/AmazingFeature)  **Open a Pull Request**  Project Link: https://github.com/<your_username>/business-editorial-bot-app  **Acknowledgments**  OpenAI Streamlit  **License**  Distributed under the MIT License. See LICENSE for more information."
,"# ü§ñ GPT For Y'all: A Streamlit-based Language Model Application  This repository contains code for a Streamlit application that leverages language models for various tasks üìö. The application includes functionalities for basic language generation üí¨, creative writing ‚úç, text summarization üìù, few-shot learning üéØ, and Python code generation üêç.  ## üåü Features  The Streamlit application provides an interface for the following tasks:  1. **Base Generation** üí¨: This feature is for standard language generation tasks. Users can provide a prompt, and the application will generate a response based on the input.  2. **Creative Writing** ‚úç: This feature allows users to generate creative content, such as stories or poems. Like base generation, it requires a user-provided prompt.  3. **Text Summarization** üìù: This feature enables users to summarize long blocks of text. It requires a large text input from the user and generates a summarized version of the input.  4. **Few-Shot Learning** üéØ: This feature is useful for performing few-shot learning. Users can provide a set of examples and a prompt, and the application will generate a response based on the given examples and the prompt.  5. **Python Code Generation** üêç: This feature leverages a Python agent for generating Python code based on user prompts.  ## üìñ Usage  To use the application, you need to provide your OpenAI API Key and a path to the weights for your GPT model.  For each feature, you can input your prompt or text into the input box and hit 'Enter' üñ±. The application will generate and display the response.  ## üõ† Installation and Setup  The application requires Python and Streamlit. Other dependencies are included in the `requirements.txt` file.  To set up and run the application, follow these steps:  1. Clone this repository to your local machine üñ•.  2. Install the necessary dependencies by running `pip install -r requirements.txt` üì¶.  3. Set up your OpenAI API Key and the path to the GPT model weights üîë.  4. Run the application using Streamlit with `streamlit run app-comparison.py` üöÄ.  ## üìö Dependencies  The main dependencies for this project are:  - [Streamlit](https://streamlit.io/): Used to build the web application interface. - [Langchain](https://github.com/hwchase17/langchain.git): Used for language generation tasks.  ## üîó Other References  - [GPT4AllReference](https://github.com/nomic-ai/gpt4all/tree/main): Mainly used to determine how to install the GPT4All library and references. The documentation was changing frequently, and at the time of coding this was the most up-to-date example of getting it running."
," # ChatGpt Question Answer  This is a simple project based on openai library , It takes a question from the user and produces the output ,searching the internet.It uses tokenizer and model taken from openai thus it produces different outputs at different time for the same question.  ## Acknowledgements  - Vinni Thakur Mam - OpenAi - [How to write a Good readme](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)   ## API Reference  The API key is taken from OpenAPI   ## Authors  - [Dhruv Sanghvi](https://github.com/DhruvSanghvi2002)   ## Appendix  The tokenizer and nlp model is taken from OpenAI ,this is the simple model to take string as an input from the user ,seperate out each words and then process it via text-davinci-003 model and produce a response ,streamlit is used for making frontend ,the project is deployed on render and the web address is https://chatgpt-fatj.onrender.com/   ## Deployment  To deploy this project run  ```bash python -m streamlit run app.py ```   ## üöÄ About Me I am a frontend developer and an Machine Learning Enthuisast , I am currently working on D.L and NLP. "
,"<!-- 1. First, install the prerequisites --> pip install -r requirements.txt  <!-- 2. Instead of using standard ""python main.py"" for launch, use next command: --> python -m streamlit run main.py --server.port 8002 "
,"# Simple query app  I'm pretty sure practically everyone and their cat has made something like this already, but basically:  This is a streamlit app that can be configured to answer natural language questions about a database table.  The slightly notable parts: - It uses a slightly modified version of llama-index, which uses column comments as additional table information - It includes an expandable ""check the answer"" section that again uses gpt to generate a human explanation of the final SQL query, which it displays together with the query.  The whole thing is in Norwegian. It works reasonably well, but errors out on complex queries (and some uncomplicated ones as well) and rarely if ever makes conditions case-insensitive.   ## Get it running  The one file that is missing in this repo is the `.env` file that contains all the secrets such as database credentials and openAI API key.  Create a file named `.env` and fill it like this:  ``` SNOWFLAKE_ACCOUNT = '<ab12345.my-region.my-cloud>' SNOWFLAKE_USER = '<my-username>' SNOWFLAKE_PASSWORD = '<my-password>' SNOWFLAKE_WAREHOUSE = '<my-warehouse>' SNOWFLAKE_DATABASE = '<my-database>' SNOWFLAKE_SCHEMA = '<my-schema-name>' OPENAI_API_KEY = '<my-openai-api-key>' ```  Additionally, you need to alter the `app.py` file to use the table you want. Database and Schema is already configured above, but the table name(s) must be set in the script itself.  ```py tables_to_query = [""<my_table_name>""] ```  Once this is done, it should suffice to run  ```sh pip install -r requirements.txt streamlit run app.py ```"
,Demo OpenAI Embeddings
,# GPT-4-Chatbot-using-ChatGPT-API-and-Streamlit-Chat Building a GPT-4 Chatbot using ChatGPT API and Streamlit Chat ![Screenshot (145)](https://github.com/harshgharat99/GPT-4-Chatbot-using-ChatGPT-API-and-Streamlit-Chat/assets/48839466/50265856-2b12-4ace-9b7a-e25d9ffb7e3d)
,Demo :  ![demo2](https://github.com/rohitf1/chatbot-streamlit-langchain-pinecone-openai/assets/110368802/b5fecbe1-065e-418c-9f07-343b20d27592)
,# openai_ai_api_bot_001 Chat GPT API x Streamlit„ÅÆ„ÉÜ„Çπ„Éà
,"# TurboGPT [![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://turbogpt.streamlit.app/)   TurboGPT is a chatbot similar to ChatGPT, powered by the GPT-3.5 language model, developed by [Tushar Aggarwal](https://tushar-aggarwal.com). This chatbot is built using Streamlit, a Python library for creating web applications. With TurboGPT, you can have interactive conversations with an AI-powered language model, making it ideal for various applications such as virtual assistants, customer support, and more. ### Note: Due to obvious reasons, an OpenAI API key is needed, I promise, TurboGPT won't store your API key, but will only store conversation history. After you exit, that too will be dumped.  ![Untitled design](https://github.com/tushar2704/TurboGPT/assets/66141195/2c4e3a06-c043-4be9-ac9d-d4ee685c0e55)   ## Features - **Natural Language Processing**: TurboGPT utilizes the advanced natural language processing capabilities of the GPT-3.5 model, allowing it to understand and generate human-like responses. - **Interactive Conversations**: Engage in interactive and dynamic conversations with TurboGPT. You can chat with the chatbot and receive real-time responses. - **Easy-to-Use Interface**: TurboGPT is built using Streamlit, which provides a user-friendly and intuitive interface for interacting with the chatbot. You can easily input your queries and view the responses in a conversational format. - **Customizable Responses**: TurboGPT can be customized to generate responses according to specific prompts or scenarios. You can tailor the chatbot's behavior to suit your application requirements. - **Application Integration**: TurboGPT can be easily integrated into existing web applications or services. You can leverage the chatbot's capabilities to enhance user experiences and provide automated assistance.  ## Getting Started  To run TurboGPT locally, follow these steps:  1. Clone the TurboGPT repository: `git clone https://github.com/tushar2704/TurboGPT.git` 2. Navigate to the project directory: `cd TurboGPT` 3. Install the required dependencies: `pip install -r requirements.txt` 4. Run the application: `streamlit run app.py` 5. Access the chatbot in your browser at `http://localhost:8501`  ## Configuration  The configuration for TurboGPT can be found in the `TurboGPT.py` file. Here, you can modify parameters such as the GPT model version, maximum response length, and more, to customize the behavior of the chatbot.    ## Limitations  While TurboGPT provides advanced natural language processing capabilities, it also has certain limitations:  - **Contextual Understanding**: The chatbot does not maintain long-term memory of previous interactions, resulting in a lack of context in ongoing conversations. - **Subjective Responses**: TurboGPT generates responses based on patterns and examples from its training data, which means it may not always provide objective or accurate information. - **Safety Concerns**: The chatbot may produce biased or inappropriate responses. It is recommended to implement content filtering and moderation mechanisms to ensure responsible usage.  ## License  TurboGPT is released under the [MIT License](https://github.com/tushar2704/TurboGPT/blob/main/LICENSE).  ## Acknowledgments  TurboGPT is based on the GPT-3.5 language model developed by OpenAI. We would like to acknowledge their contributions to the field of natural language processing and their efforts in making the GPT models accessible for developers."
,"# Streamlit ChatGPT with Azure Speech Services  This Streamlit app uses ChatGPT along with Azure Speech Services to provide an interactive and engaging chatting experience for users. Users can chat with the AI both using text input and voice input, making your experience more personalized and convenient. *** ## How to Use  1. Clone the repository:  ```bash git clone https://github.com/USERNAME/chatApp.git ```  2. Navigate to the project folder:  ```bash cd chatApp ```  3. Run the Streamlit app:  ```bash streamlit run app.py ``` *** ## Requirements  Before you begin, make sure you run ```bash pip install -r requirements.txt ``` *** ## Text  To chat with ChatGPT using text inputs, follow these steps:  1. Navigate to the sidebar and select ""Text"" from the dropdown menu. 2. Enter your [OpenAI API Key](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/#:~:text=Go%20to%20OpenAI%27s%20Platform%20website,generate%20a%20new%20API%20key.) and hit Enter. 3. The chat window should appear in the main page. 4. Type your chats in the box provided and hit Enter to send your messages. *** ## Voice  To chat with ChatGPT using voice inputs through Azure Speech Services, follow these steps:  1. Navigate to the sidebar and select ""Voice"" from the dropdown menu. 2. Enter your [OpenAI API Key](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/#:~:text=Go%20to%20OpenAI%27s%20Platform%20website,generate%20a%20new%20API%20key.) and your [Azure Speech Subscription Key](https://carldesouza.com/get-a-microsoft-cognitive-services-subscription-key/). 3. The bot should greet you right away. 4. When you see ""Speak Now"" you may speak, and when you see ""Speech received"" along with a transcript of what it received, the bot is preparing to respond. When you see ""Speech received"" become grayed out, you may speak again. 5. Listen to the AI-generated response through your speakers or headphones.  *NOTE: You need to have an Azure Speech Services subscription key to use the voice input feature. Also the conversation will be just like the chat bot, so you must wait until the bot finishes speaking before talking.  Enjoy your chatting experience with Streamlit ChatGPT with Azure Speech Services!"
,"# ChatBotGPT ChatBot with Python Streamlit and GPT API  # Lancer le ChatBot Pour lancer le ChatBot, il faut tout d'abord cr√©er un environnement python virutel et installer les requirements via le fichier requirements.txt  Une fois que cela est fait, il suffit de lancer la commande suivante : streamlit run chatbot.py  # Probl√®me  Le probl√®me de l'application est le fait de devoir payer afin de recevoir les requ√™tes de GPT. Si vous voulez changer la cl√© API afin de faire fonctionner l'application, rendez-vous sur le fichier .env et rentrer votre cl√© API que vous trouverez sur le site OPENAI. Il vous faut donc une cl√© API poss√©dant un abonnement afin de recevoir les r√©sultats. Voici le lien pour r√©cup√©rer la cl√© API : https://platform.openai.com/account/api-keys et celui pour payer : https://platform.openai.com/account/billing/overview  # Utilisation de l'application  Il suffit de rentrez une requ√™te et le Bot vous r√©pondra : <img width=""1440"" alt=""image"" src=""https://github.com/MelvinCRNR/ChatBotGPT/assets/43339150/baf11d44-396b-431d-be10-3122bc64a093"">"
,# È°πÁõÆÁÆÄ‰ªã - Êó®Âú®ÂÆûÁé∞‰∏Ä‰∏™Âü∫‰∫éstreamlitÂíåchatgptÁöÑÊúÄÁÆÄÁâàÁöÑchatbot webÂÆ¢Êà∑Á´Ø - ÂèÇËÄÉÈ°πÁõÆÔºöhttps://github.com/marshmellow77/streamlit-chatgpt-ui  # Ëø≠‰ª£ÂÜÖÂÆπ - ‰øÆÂ§ç‰∫ÜÂÆ¢Êà∑Á´ØÂú®Êèê‰∫§Êó∂‰ºöÈáçÂ§çÊòæÁ§∫ÊñáÊú¨Ê°ÜÂíåÊèê‰∫§ÊåâÈíÆÁöÑÈóÆÈ¢ò - Ë∞ÉÊï¥‰∫ÜÈ°µÈù¢ÂõæÊ†á„ÄÅ‰∫∫Áâ©ÂõæÊ†á„ÄÅÈ°µÈù¢Ê†áÈ¢òÁ≠âÂÜÖÂÆπ  # ‰ΩøÁî®ÊñπÊ≥ï - ÈÖçÁΩÆ.envÊñá‰ª∂‰∏≠ÁöÑopenai key - ÂÆâË£Östreamlit„ÄÅstreamlit_chatÂ∫ì - Âú®Êñá‰ª∂ÊâÄÂú®ÁõÆÂΩï‰∏ãÔºåËøêË°åÔºöstreamlit run app.py  # ÂÆûÁé∞ÈÄªËæë‰ªãÁªç - ÂâçÁ´ØÈ°µÈù¢ÂÖÉÁ¥†ÈááÁî®streamlitÊ°ÜÊû∂ÁîüÊàê - ‰ΩøÁî®streamlit_chatÂ∫ìÊù•ÂëàÁé∞ÂØπËØùÂÜÖÂÆπÔºåÈÄöËøáÂà∂ÂÆöÂØπËØùËÄÖÁöÑË∫´‰ªΩÔºåÂèØ‰ª•Ëá™Âä®ÁöÑÂ∞ÜuserÂÜÖÂÆπÈù†Âè≥Â±ïÁ§∫ÔºåaiÂÜÖÂÆπÈù†Â∑¶Â±ïÁ§∫ - ‰ΩøÁî®st.session_state‰øùÂ≠òÂéÜÂè≤ÂØπËØù‰ø°ÊÅØÔºåÂà∑Êñ∞È°µÈù¢Âêést.session_stateÂÜÖÂÆπÊ∏ÖÁ©∫ - demo‰∏≠ÈªòËÆ§‰ΩøÁî®gpt-3.5-turboÂéüÁîüÊé•Âè£ÔºåÂèØËá™Ë°åÊõøÊç¢‰∏∫ÂÖ∂ÂÆÉLLMÊé•Âè£
,# gpt-true-or-false Streamlit app where GPT answers True or False
,"# PDF LLM-Chat App (Langchain & FAISS)  ![Python](https://img.shields.io/badge/Language-Python-blue?logo=python) ![Streamlit](https://img.shields.io/badge/Tool-Streamlit-orange?logo=streamlit) ![Langchain](https://img.shields.io/badge/Tool-Langchain-yellow?logo=langchain) ![FAISS](https://img.shields.io/badge/Tool-FAISS-red?logo=faiss) ![OpenAI](https://img.shields.io/badge/Tool-OpenAI-lightblue?logo=openai)  > A web application built using Langchain and Streamlit to allow users to upload their PDF files and chat with them. It leverages OpenAI API to process the PDF content and FAISS to create a vector database for efficient similarity search.  ## Table of Contents  - [Introduction](#introduction) - [Features](#features) - [Installation](#installation) - [Usage](#usage) - [Technologies](#technologies) - [Contributing](#contributing) - [License](#license)  ## Introduction  ![My Image](my_image.png)  The PDF Chat App is a user-friendly web application that facilitates the upload of PDF files and enables users to engage in a chat-like interaction with their uploaded documents. By utilizing Langchain and Streamlit, this app offers a seamless experience for users to interact with their PDF content in a conversational manner.  The core functionality of the app relies on the OpenAI API, which processes the content of the PDF files to enable intelligent interactions. Additionally, the application leverages FAISS, a library for efficient similarity search, to create a vector database for the uploaded PDF files, allowing users to perform quick searches and retrieve similar documents.  ## Features  - Upload and process PDF files - Chat-like interface for interacting with PDF content - Intelligent processing of PDF content using the OpenAI API - Efficient similarity search using FAISS - User-friendly and intuitive interface  ## Installation  1. Clone the repository:  ```shell git clone https://github.com/avikshit-banerjee/LLM-PDF-Chat-app.git ```  2. Change to the project directory:  ```shell cd pdf-chat-app ```  3. Install the required dependencies:  ```shell pip install -r requirements.txt ```  ## Usage  1. Run the Streamlit app:  ```shell streamlit run app.py ```  2. Open your web browser and navigate to `http://localhost:8501` to access the PDF Chat App.  3. Upload your desired PDF file(s) to the app.  4. Engage in a chat-like interaction with your PDF content.  ## Technologies  The following technologies were used in the development of this project:  - ![Python](https://img.shields.io/badge/Language-Python-blue?logo=python): The primary programming language for building the application. - ![Streamlit](https://img.shields.io/badge/Tool-Streamlit-orange?logo=streamlit): The framework used for creating the web interface. - ![Langchain](https://img.shields.io/badge/Tool-Langchain-yellow?logo=langchain): LangChain is a framework for developing applications powered by language models. - ![FAISS](https://img.shields.io/badge/Tool-FAISS-red?logo=faiss): A library for efficient similarity search, utilized for creating a vector database for the PDF files. - ![OpenAI](https://img.shields.io/badge/Tool-OpenAI-lightblue?logo=openai): The OpenAI API is employed to process the PDF content and enable intelligent interactions.  ## Contributing  Contributions are welcome! If you find any issues or have suggestions for improvements, please feel free to open an issue or submit a pull request.  ## License  This project is licensed under the [MIT License](LICENSE)."
,# gpt_api_front A front end to use test the utility of chat gpt¬¥s api  # How to Run 1. Place your OpenAI apikey in the file my apikey.txt 2. Ensure you have the require libraries 3. Execute the file run_front.bat  # Sample Files  ## Text Generation ![image](https://github.com/fmurphy97/gpt_api_front/assets/88452698/6f851ab3-23e4-4539-919c-adf51f099c59)  ## Image Generation ![image](https://github.com/fmurphy97/gpt_api_front/assets/88452698/fffec585-b5da-45a3-98a5-e0d9e36547b5) 
,"<img src=""https://i.imgur.com/3hgDsT0.png"" width=""200"" height=""200"" align=""center""/>  # JancoBot A chatbot that is leveraging GPT-4, Langchain Framework and StreamLit to simulate a convo with Jean-Marc Jancovici  ![alt text](https://i.imgur.com/rbV0BPM.png) ## How to run 1. Install the requirements with `pip install -r requirements.txt` 2. Add your LLM global prompt in a file called `prompt.py` such as : ```python janco_prompt = """"""..."""""" ``` 3. Add your OpenAI API key to your environment variables OR add it to a file called `.env` such as : ``` OPENAI_API_KEY=... ``` 4. Run the app with `streamlit run app.py` 5. Enjoy!  ## Papar Information - Title:  `JancoBot` - Authors:  `Joris Carol`  ## Install & Dependence langchain==0.0.177 openai streamlit==1.22.0 streamlit_chat==0.0.2.2 easyocr==1.7.0 backports.zoneinfo==0.2.1;python_version<""3.8"" faiss-cpu==1.7.4 tiktoken==0.4.0 typing-inspect==0.8.0 typing_extensions==4.5.0 python-dotenv youtube-transcript-api  ## Directory Hierarchy ``` |‚Äî‚Äî .gitignore |‚Äî‚Äî App.py |‚Äî‚Äî __pycache__ |    |‚Äî‚Äî prompt.cpython-38.pyc |‚Äî‚Äî jancobot |    |‚Äî‚Äî .gitignore |    |‚Äî‚Äî App.py |    |‚Äî‚Äî README.md |‚Äî‚Äî prompt.py |‚Äî‚Äî requirements.txt ```"
,"# OpenAI Movie Concept and Poster Generation Streamlit Web App Python Streamlit web app utilizing LangChain and the OpenAI API GPT 3.5 Turbo language model to generate example movie concepts based on the AI director(Spike Lee, Quentin Tarrentino, Wes Anderson) and user input, and then the DALLE2 image generation model to generate relevent movie poster.  ## Version 2 Example Screenshots 1. Improved code formatting and modularity 2. Improved prompt for movie poster generation to better allign with director ![image](https://github.com/petermartens98/OpenAI-LangChain-Movie-Concept-and-DALLE2-Poster-Generation-Streamlit-Web-App/assets/87671757/8ffa2e9a-8a1a-4bd1-ab44-0d4737d92b60) ![image](https://github.com/petermartens98/OpenAI-LangChain-Movie-Concept-and-DALLE2-Poster-Generation-Streamlit-Web-App/assets/87671757/ac08ed24-ffd3-4ead-b3b6-893eb6d69598) ![image](https://github.com/petermartens98/OpenAI-LangChain-Movie-Concept-and-DALLE2-Poster-Generation-Streamlit-Web-App/assets/87671757/afb07cf3-f058-4b9c-90d0-473b736ff182)   ## Version 1 Example Screenshots ![image](https://github.com/petermartens98/OpenAI-Movie-Concept-and-Poster-Generation-Streamlit-Web-App/assets/87671757/5e8e9938-d988-41b8-a964-d56840024b79) ![image](https://github.com/petermartens98/OpenAI-Movie-Concept-and-Poster-Generation-Streamlit-Web-App/assets/87671757/220d0f3c-467f-4898-b8e4-3168dea40070) ![image](https://github.com/petermartens98/OpenAI-Movie-Concept-and-Poster-Generation-Streamlit-Web-App/assets/87671757/bf4ab2a4-3ca7-4e0f-874d-d36cdb161147)"
,# Meal-Planner Uses GPT-2 + Langchain + Hugging Face API + Streamlit to make a simple meal plan generator app
,"# KinskiGPT: A Klaus Kinski Conversational Bot  KinskiGPT is an application utilizing OpenAI's GPT model to simulate a chat with the legendary, passionate, and often controversial figure of German cinema and theater, Klaus Kinski. The chatbot embraces Kinski's famous tantrums and insults, creating a dynamic and authentic conversation experience.  ## Project Structure  This Python script is a web application that makes use of the Streamlit library for user interface and the OpenAI API for conversation generation. The OpenAI API key is securely loaded from an environment file.  ## Dependencies  The main libraries and packages used in this project are:  - `openai` for interaction with OpenAI's GPT-3 model - `os` for environment variable management - `dotenv` for .env file handling - `streamlit` for web application framework  Please ensure that these packages are installed in your environment before running the application.  ## Installation  1. Install the required Python packages if you haven't done so. This can be done by running the following command in the project's root directory:  ```bash pip install -r requirements.txt ```  2. Clone this repository to your local machine.  3. Create a `.env` file in the root directory of the project. Inside this file, set the following variable: ```bash OPENAI_API_KEY=<Your_OpenAI_API_Key> ```  ## Usage  To start the application, run the Python script with Streamlit. From the project's root directory, enter the following command:  ```bash streamlit run main.py ```  This command will start a local server, and you can interact with the KinskiGPT in your web browser.  ## Functionality  The main interface of KinskiGPT comprises a chat window and a text input field. After typing a message into the input field and pressing enter, the message is sent to the GPT model, which generates a response in the persona of Klaus Kinski.  The model has a pre-loaded system prompt that introduces the persona of Kinski and encourages the user to engage with the bot in a manner that stimulates the 'Klaus Kinski' responses.  ## Examples  ### English ![Example english](image.png)  ### German ![Example german](image2.png)  ## Limitations  As of the current build, the chat history is not saved when the session ends or when the server is stopped. Any ongoing chat history will be lost when the page is refreshed.  ## Contribution  This is an open-source project. Feel free to fork and make your own changes or propose improvements by making a pull request.  ## Disclaimer  This codebase is intended for educational and demonstration purposes. It is not intended to fully or accurately represent or simulate Klaus Kinski, who was a real person with a nuanced personality and life history. The simulated conversations generated by this program are based on training data used to train the GPT model and may not reflect actual statements or views held by Klaus Kinski."
,# CustomPDF_GPT Aim: Build a Custom PDF GPT APP using LangChain & StreamLit
,# Website-Q-A Uses GPT-3 + Langchain + Open AI API + Streamlit to make a simple Website Q&amp;A app that can take any document or website and answer questions
,"# AutoJobResume I will use LLM GPT-3, python for pull requests, streamlit to preview it. Next steps: Will add web scraping to get key info from websites of companies and use that in resume, will train model on 'exceptional' resumes for targeted results, and will fully automate it so that only based on your own resume, the model will apply to companies on its own."
,"# clinicaltrials_ai Streamlit app of ChatGPT that can use the clinical-trials.gov API. Better with GPT-4.  Just set your openai api key as an environment variable ""OPENAI_API_KEY"", and run via streamlit: streamlit run app.py  See streamlit docs for more help."
,# Description CodeGPT is a Streamlit web application that streamlines the process of generating code from plain English text prompts. It leverages the power of the OpenAI API and the GPT-3.
,"<!--- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License.  You may obtain a copy of the License at  http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License. -->  The ORC and JSON files come from the `examples` directory in the Apache ORC source tree: https://github.com/apache/orc/tree/main/examples"
,# Cover-Letter-Generator Generate a cover letter using GPT 3 and a simple Web UI maded in Streamlit.
,"# GPT4-Coding-Assistant-Web-App ### Description Python Streamlit web app utilizing OpenAI (GPT-4) and LangChain language modeling tools. Application includes an SQLite database for login/authentication and message storage for later retrieval. Users can also upload and embed their own PDF documents for chatbot reference. The user can then interact with a GPT-4 chatbot intended for the user's specified programming language, code input, context, scenario, LLM temperature, and chat history.  ### Supported Scenarios 1. General Assistant 2. Code Correction 3. Code Completion 4. Code Commenting 5. Code Optimization 6. Code Shortening 7. Code Generation 8. Code Explanation 9. LeetCode Solver  ### Supported Programming Languages 1. Python 2. TypeScripts 3. JavaScript 4. Java 5. Golang 6. C 7. C++ 8. C# 9. R 10. SQL  ### Supported Large Language Models 1. GPT-4 2. GPT-4-0613 3. GPT-3.5-Turbo  ## V7 ### V7 Improvements 1. Added User Login and Authentication System (SQLite) 2. Save User Messages (SQLite) 3. View and Revive Previous Chats ### V7 Screenshot ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/2467d134-cf1a-46a9-9ed6-4deb57a426de)   ## V6 ### V6 Improvements 1. Allow users to upload and embed multiple documents 2. Allow users to specify a desired library within their specified programming language 3. Allow users to specify their desired large language model ### V6 Example Screenshot ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/688eb70b-e84e-4dcc-9f68-a05ca414d665)   ## V5 ### Improvements ### 1. Added support for SQL ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/a46515b5-20a2-41ef-8330-dbdb46ccae79)  ### 2. Added Code Shortening Mode ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/f9f4380e-411c-48d5-ada6-366d56f30c57)  ### 3. Added Leet Code Solver ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/07d6ff64-2f71-4687-82d3-d84f297b3eb0)  ### 4. Added Code to display source code ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/5ebb8827-0d01-418a-b650-bff087e95478)  ## V4 Improved code modularity  ## V3 ### V3 General Assistant Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/6e35f3cf-fa60-47cb-b6f8-533dbf89072c)  ### V3 Code Completion Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/9c4fa802-468f-4899-b2c2-bc5bc7b05ef9)  ### V3 Code Correction Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/1ffe61e2-2f73-4a47-b11c-8aee0b9f0b8c)  ### V3 Code Commenting Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/701eb2c6-8321-4c43-b06f-0df728c03858)  ### V3 Code Optimization Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/bf796215-328d-41b7-919b-62f669ed4e61)  ### V3 Code Explanation Screenshot: ![image](https://github.com/petermartens98/GPT4-Programming-Assistant/assets/87671757/f5ace256-8a75-4a10-a6c6-07d93f579535)  ## V2 ### V2 Code Completion Screenshot ![image](https://github.com/petermartens98/GPT4-Coding-Assistant-Web-App/assets/87671757/f6b251e8-c989-480b-9e1e-c5a041b7ebab)  ### V2 Code Correction Screenshot ![image](https://github.com/petermartens98/GPT4-Coding-Assistant-Web-App/assets/87671757/98ac7b0a-df63-42b1-8ec4-d57bd24b1711)  ## V1 ### V1 Code Correction Screenshot ![image](https://github.com/petermartens98/GPT4-Coding-Assistant-Web-App/assets/87671757/0a09df8d-f457-4d9c-842e-8dc8e757ad96)"
,"# News Sense ### A Streamlit app based on Python that fetches top news articles from the News API, generates a summary of each article using the OpenAI GPT-3 model, analyzes the sentiment of the article using the NLTK library, and classifies the article into different categories based on keywords.  ## Setup Before running the script, make sure you have the following dependencies installed: - `requests`: To make HTTP requests to the News API. - `openai`: To interact with the OpenAI GPT-3 model. - `nltk`: To perform sentiment analysis using the VADER lexicon.  You can install the dependencies using the following command: ``` pip: -r requirements.txt ```  Additionally, you need to download the VADER lexicon by running the following code once: ```python import nltk nltk.download('vader_lexicon') ```  ## API Keys To use the script, you need to provide your API keys for the News API and the OpenAI GPT-3 API. Replace the placeholder values with your actual API keys in the `secrets.toml` file: ```python NEWS_API_KEY = """" CHATGPT_API_KEY = ""sk-"" ```  ## Functionality The script provides the following functions: - `get_news_articles()`: Fetches the top news articles from the News API. It returns a list of articles. - `generate_summary(text)`: Generates a summary of the given text using the OpenAI GPT-3 model. It returns the generated summary. - `analyze_sentiment(text)`: Analyzes the sentiment of the given text using the VADER lexicon from NLTK. It returns a dictionary of sentiment scores. - `classify_article(text)`: Classifies the article into different categories based on keywords present in the text. It returns a list of categories. - `main()`: The main function that fetches news articles, generates summaries, analyzes sentiments, and classifies articles. It prints the title, URL, summary, sentiment, and categories for each article.  ## Usage To use the script, simply run the following command: ``` streamlit run getNewsSense.py ``` The script will fetch the top news articles, generate summaries, analyze sentiments, and classify articles. The results will be printed for each article. The script uses the `davinci` engine from the OpenAI GPT-3 model. Make sure you have sufficient credits or subscription to use the model effectively.  ## Screenshot ![Screenshot](screenshot.JPG)  ## License [MIT License](https://github.com/tanmaychk/news-sense/blob/main/LICENSE)"
,"## Template for creating your own ChatGPT with Streamlit and OpenAI API  This repository contains the code for a simple web application built with [Streamlit](https://streamlit.io/), which uses OpenAI's GPT-3 model for generating AI responses in a chat-like interface.  ### Prerequisites 1. Python 3.6 or above 2. An OpenAI API Key  ### App Demo ![StreamlitChatbot](https://github.com/krisograbek/streamlit_chatbot_base/assets/48050596/e1c62c71-0b3d-4a3b-9855-e48fc73e402b)   ### Steps to run the application **1. Clone the repository to your local machine:** ```shell git clone https://github.com/krisograbek/streamlit_chatbot_base.git ```  **2. Navigate to the project directory:** ```shell cd streamlit_chatbot_base ```  3. Create a virtual environment and activate it:  On macOS and Linux: ```shell python3 -m venv myenv source myenv/bin/activate ```  On Windows: ```shell python -m venv myenv .\myenv\Scripts\activate ```  3a. Upgrade pip (optional but recommended) ```shell pip install --upgrade pip ```  4. Install the necessary Python packages: ```shell pip install -r requirements.txt ```  5. Create a .env file in the root directory of the project and add your OpenAI API key: ```shell echo OPENAI_API_KEY=your-api-key > .env ``` OR  ```shell cp .env.example .env ```  Please replace your-api-key with your actual OpenAI API key.  6. Run the Streamlit application: ```shell streamlit run chatbot.py ```  Open a web browser and navigate to http://localhost:8501 to interact with the application.  License This project is open source, under the terms of the MIT license.  Note: This app makes requests to OpenAI's servers whenever the chat is used. Please be aware of this, especially if you're on a paid plan with OpenAI."
,"# OpenAI-Customizable-Chat-Bot- Python Streamlit web app utilizing the OpenAI API GPT 3.5 Turbo language model. The app has a sidebar that allows the user to change and initiate new chate based on user defined settings such as language model, personality, context, and response temperature.  ## Example Screenshot ![image](https://github.com/petermartens98/OpenAI-Customizable-Chat-Bot-/assets/87671757/858f4e52-b1fd-442f-a6b9-2f3d7bdf3a5e)"